{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LionAGI - 103\n",
    "\n",
    "**Reflective Iterative editing** of a piece of text\n",
    "\n",
    "and \n",
    "\n",
    "**Structured Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lionagi import iModel, Branch\n",
    "\n",
    "config = {\n",
    "    \"provider\": \"openai\",\n",
    "    \"api_key_schema\": \"OPENAI_API_KEY\",\n",
    "}\n",
    "\n",
    "gpt4o = iModel(model=\"gpt-4o\", **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing custom logic to LLM flow\n",
    "\n",
    "---\n",
    "\n",
    "Now we can do something more complex other than having LLMs following through a pre-defined flow. We can introduce custom logic to the LLM flow. \n",
    "\n",
    "But first let's take a look at `structured_output`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM works by taking a bunch of texts and generate a bunch of texts. Natural Language Processing (NLP) isn't necessarily easy to to help us make use of the response, and one way to mitigate that is **structured output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going back to the comedian example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedian_system_message = \"a respected zoo keeper, also a comedian who knows very well about indian post modern literature\"\n",
    "critic_system_message = \"As an a young professor, you are trying to get into the prestigious circle of literature criticism.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch = Branch(system=comedian_system_message, imodel=gpt4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here's a light-hearted take:\n",
       "\n",
       "A blue whale and a big white shark walk into a bar. The bartender looks up and says, \"Wow, we don't get many of your kind in here!\" \n",
       "\n",
       "The blue whale replies, \"Well, we heard the drinks here are killer!\" \n",
       "\n",
       "The shark nods and adds, \"And I heard the dance floor is a real splash!\"\n",
       "\n",
       "So, they both hit the dance floor, and the whale starts doing the worm. The shark looks over and says, \"Hey, I thought you were more of a 'wave' kind of dancer!\"\n",
       "\n",
       "The whale chuckles and says, \"Nah, I just like to keep things current!\"\n",
       "\n",
       "And with that, they both danced the night away, making waves and having a whale of a time!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt1 = \"Tell a joke: a blue whale met a big white shark in a bar, then started dancing.\"\n",
    "\n",
    "prompt2 = \"Tell a joke: an elephant knocked off a banana tree.\"\n",
    "\n",
    "response = await branch.chat(prompt1)\n",
    "printmd(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now intead of asking comedian to give a plain joke, let's instruct it to also give a few other things, by giving an example to the comedian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\n",
    "    \"category\": \"jokes\",\n",
    "    \"topic\": \"assigning personalities to animals\",\n",
    "    \"interpretation\": \"The..... therefore.....\",\n",
    "    \"joke\": \"...\",\n",
    "    \"rating\": \"an integer from 1 to 10\",\n",
    "}\n",
    "\n",
    "response = await branch.chat(instruction=prompt2, requested_fields=example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"category\": \"jokes\",\n",
      "    \"topic\": \"assigning personalities to animals\",\n",
      "    \"interpretation\": \"The joke plays on the idea of elephants being large and clumsy, therefore humorously causing unintended chaos.\",\n",
      "    \"joke\": \"Why did the elephant knock off the banana tree? Because it wanted to make a little 'a-peel' in the jungle!\",\n",
      "    \"rating\": 7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from lionfuncs import as_readable_json\n",
    "\n",
    "print(as_readable_json(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can see that the comedian can give us a joke, a joke type, and a joke rating. By making the output a `dict` we can effectively use the output of the comedian. \n",
    "\n",
    "We asked it to give itself a rating, here is an example to use it: \n",
    "\n",
    "ask comedian to repeat fixing this joke until it reaches **8/10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def reflective_joke(prompt, max_attempts=3):\n",
    "\n",
    "    response = await branch.chat(\n",
    "        instruction=prompt,\n",
    "        requested_fields=example,\n",
    "    )\n",
    "\n",
    "    print(as_readable_json(response))\n",
    "\n",
    "    while response[\"rating\"] < 8 and max_attempts > 0:\n",
    "        print(\"-------------- Not a great joke, trying again --------------\")\n",
    "        response = await branch.chat(\n",
    "            instruction=\"try again\",\n",
    "            requested_fields=example,\n",
    "        )\n",
    "        print(as_readable_json(response))\n",
    "        max_attempts -= 1\n",
    "\n",
    "    if response[\"rating\"] >= 8:\n",
    "        print(\"-------------- Great joke! --------------\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"category\": \"jokes\",\n",
      "    \"topic\": \"assigning personalities to animals\",\n",
      "    \"interpretation\": \"The joke highlights the elephant's size and strength, therefore humorously attributing its clumsiness to its massive presence.\",\n",
      "    \"joke\": \"Why did the elephant knock off the banana tree? It just couldn't resist a little 'trunk' show!\",\n",
      "    \"rating\": 6\n",
      "}\n",
      "-------------- Not a great joke, trying again --------------\n",
      "{\n",
      "    \"category\": \"jokes\",\n",
      "    \"topic\": \"assigning personalities to animals\",\n",
      "    \"interpretation\": \"The joke plays on the elephant's reputation for being both strong and somewhat clumsy, therefore humorously causing unintended consequences.\",\n",
      "    \"joke\": \"Why did the elephant knock off the banana tree? It wanted to start a 'fruitful' conversation!\",\n",
      "    \"rating\": 7\n",
      "}\n",
      "-------------- Not a great joke, trying again --------------\n",
      "{\n",
      "    \"category\": \"jokes\",\n",
      "    \"topic\": \"assigning personalities to animals\",\n",
      "    \"interpretation\": \"The joke uses the elephant's size and strength to create a humorous scenario, therefore attributing its actions to its playful nature.\",\n",
      "    \"joke\": \"Why did the elephant knock off the banana tree? It was just trying to make a 'smoothie' entrance!\",\n",
      "    \"rating\": 8\n",
      "}\n",
      "-------------- Great joke! --------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'jokes',\n",
       " 'topic': 'assigning personalities to animals',\n",
       " 'interpretation': \"The joke uses the elephant's size and strength to create a humorous scenario, therefore attributing its actions to its playful nature.\",\n",
       " 'joke': \"Why did the elephant knock off the banana tree? It was just trying to make a 'smoothie' entrance!\",\n",
       " 'rating': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await reflective_joke(prompt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
