from typing import List, Optional, Union, Literal
from pydantic import BaseModel, Field


class ContentBlock(BaseModel):
    type: str
    text: Optional[str] = None


class ImageSource(BaseModel):
    type: Literal["base64"] = "base64"
    media_type: Literal["image/jpeg", "image/png", "image/gif", "image/webp"]
    data: str


class ImageContentBlock(ContentBlock):
    type: Literal["image"] = "image"
    source: ImageSource


class Message(BaseModel):
    role: Literal["user", "assistant"]
    content: Union[str, List[Union[ContentBlock, ImageContentBlock]]]


class ToolChoice(BaseModel):
    type: Literal["auto", "any", "tool"] = Field(
        description="How the model should use the provided tools."
    )
    name: Optional[str] = Field(
        default=None,
        description="The name of the specific tool to use, if type is 'tool'.",
    )


class Tool(BaseModel):
    name: str = Field(description="Name of the tool.")
    description: Optional[str] = Field(
        description="Optional, but strongly-recommended description of the tool."
    )
    input_schema: dict = Field(description="JSON schema for the tool input shape.")


class Usage(BaseModel):
    input_tokens: int = Field(description="The number of input tokens which were used.")
    cache_creation_input_tokens: Optional[int] = Field(
        description="(prompt caching beta) The number of input tokens used to create the cache entry."
    )
    cache_read_input_tokens: Optional[int] = Field(
        description="(prompt caching beta) The number of input tokens read from the cache."
    )
    output_tokens: int = Field(
        description="The number of output tokens which were used."
    )


class AnthropicMessagesRequestBody(BaseModel):
    model: str = Field(description="The model that will complete your prompt.")
    messages: List[Message] = Field(description="Input messages.")
    max_tokens: int = Field(
        description="The maximum number of tokens to generate before stopping."
    )
    metadata: Optional[dict] = Field(
        default=None, description="An object describing metadata about the request."
    )
    stop_sequences: Optional[List[str]] = Field(
        default=None,
        description="Custom text sequences that will cause the model to stop generating.",
    )
    stream: Optional[bool] = Field(
        default=None,
        description="Whether to incrementally stream the response using server-sent events.",
    )
    system: Optional[str] = Field(default=None, description="System prompt.")
    temperature: Optional[float] = Field(
        default=1.0, description="Amount of randomness injected into the response."
    )
    tool_choice: Optional[ToolChoice] = Field(
        default=None, description="How the model should use the provided tools."
    )
    tools: Optional[List[Tool]] = Field(
        default=None, description="Definitions of tools that the model may use."
    )
    top_k: Optional[int] = Field(
        default=None,
        description="Only sample from the top K options for each subsequent token.",
    )
    top_p: Optional[float] = Field(default=None, description="Use nucleus sampling.")


class AnthropicMessagesResponseBody(BaseModel):
    id: str = Field(description="Unique object identifier.")
    type: Literal["message"] = Field(default="message", description="Object type.")
    role: Literal["assistant"] = Field(
        default="assistant", description="Conversational role of the generated message."
    )
    content: List[ContentBlock] = Field(description="Content generated by the model.")
    model: str = Field(description="The model that handled the request.")
    stop_reason: Optional[
        Literal["end_turn", "max_tokens", "stop_sequence", "tool_use"]
    ] = Field(description="The reason that we stopped.")
    stop_sequence: Optional[str] = Field(
        description="Which custom stop sequence was generated, if any."
    )
    usage: Usage = Field(description="Billing and rate-limit usage.")
